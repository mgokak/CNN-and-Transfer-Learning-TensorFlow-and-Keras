{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueCDDLbngYyk"
      },
      "outputs": [],
      "source": [
        "# VGG-16 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import zipfile\n",
        "import requests\n",
        "import glob as glob\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
        "from dataclasses import dataclass\n",
        "\n",
        "block_plot = False\n",
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "SEED_VALUE = 42"
      ],
      "metadata": {
        "id": "iTBZhLt9kpNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def system_config():\n",
        "\n",
        "    # Get list of GPUs.\n",
        "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "    print(gpu_devices)\n",
        "\n",
        "    if len(gpu_devices) > 0:\n",
        "        print('Using GPU')\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "        # If there are any gpu devices, use first gpu.\n",
        "        tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
        "\n",
        "        # Grow the memory usage as it is needed by the process.\n",
        "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
        "\n",
        "        # Enable using cudNN.\n",
        "        os.environ['TF_USE_CUDNN'] = \"true\"\n",
        "    else:\n",
        "        print('Using CPU')\n",
        "\n",
        "system_config()"
      ],
      "metadata": {
        "id": "O6x5VE2AksUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Extract Dataset\n",
        "def download_file(url, save_name):\n",
        "    url = url\n",
        "    file = requests.get(url)\n",
        "\n",
        "    open(save_name, 'wb').write(file.content)"
      ],
      "metadata": {
        "id": "sEXEh9_Hk2V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(zip_file=None):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(\"Extracted all\")\n",
        "    except:\n",
        "        print(\"Invalid file\")"
      ],
      "metadata": {
        "id": "URiE-Oybk5bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_file(\n",
        "    'https://www.dropbox.com/s/6nrjxr2ycnpcy63/dataset_balls.zip?dl=1',\n",
        "    'dataset_balls.zip'\n",
        ")\n",
        "\n",
        "unzip(zip_file='dataset_balls.zip')"
      ],
      "metadata": {
        "id": "j2R1_8XBk8cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Training Configuration\n",
        "@dataclass(frozen=True)\n",
        "class DatasetConfig:\n",
        "    NUM_CLASSES: int = 10\n",
        "    IMG_HEIGHT:  int = 224\n",
        "    IMG_WIDTH:   int = 224\n",
        "    CHANNELS:    int = 3\n",
        "    BATCH_SIZE:  int = 32\n",
        "    DATA_ROOT_TRAIN: str = './dataset_balls/train'\n",
        "    DATA_ROOT_VALID: str = './dataset_balls/valid'\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainingConfig:\n",
        "    BATCH_SIZE:     int   = 32\n",
        "    EPOCHS:         int   = 51\n",
        "    LEARNING_RATE:  float = 0.0001\n",
        "    CHECKPOINT_DIR: str   = './saved_models_balls.keras'"
      ],
      "metadata": {
        "id": "bAbDsIgIk-_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG-16 Convolutional Base\n",
        "input_shape = (DatasetConfig.IMG_HEIGHT, DatasetConfig.IMG_WIDTH, DatasetConfig.CHANNELS)\n",
        "\n",
        "print('Loading model with random initial weights...')\n",
        "vgg16_conv_base = tf.keras.applications.vgg16.VGG16(input_shape=input_shape,\n",
        "                                                    include_top=False, # We will supply our own top.\n",
        "                                                    weights=None,\n",
        "                                                   )\n",
        "# Top = False, doesnot include the fully connected / dense layers\n",
        "\n",
        "# Explicity set the `trainable` attribute of the model (this is the default).\n",
        "vgg16_conv_base.trainable = True\n",
        "print('All weights trainable, fine tuning...')"
      ],
      "metadata": {
        "id": "-Q3bOJt9lH4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg16_conv_base.summary())"
      ],
      "metadata": {
        "id": "WCzHB5QZlV08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Classification Layer, new Dense Classifier\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
        "\n",
        "x = vgg16_conv_base(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "# The final `Dense` layer with the number of classes.\n",
        "outputs = layers.Dense(DatasetConfig.NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# The final model.\n",
        "vgg16_model = keras.Model(inputs, outputs)\n",
        "\n",
        "print(vgg16_model.summary())"
      ],
      "metadata": {
        "id": "6PNC7NLxlYNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training and validation dataset\n",
        "train_dataset = image_dataset_from_directory(directory=DatasetConfig.DATA_ROOT_TRAIN,\n",
        "                                             batch_size=TrainingConfig.BATCH_SIZE,\n",
        "                                             seed=SEED_VALUE,\n",
        "                                             label_mode='categorical',\n",
        "                                             image_size=(DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT),\n",
        "                                             )\n",
        "\n",
        "valid_dataset = image_dataset_from_directory(directory=DatasetConfig.DATA_ROOT_VALID,\n",
        "                                             batch_size=TrainingConfig.BATCH_SIZE,\n",
        "                                             seed=SEED_VALUE,\n",
        "                                             label_mode='categorical',\n",
        "                                             image_size=(DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT),\n",
        "                                             )\n",
        "\n",
        "# You can use the object attribute (class_names) to access the class names in the dataset.\n",
        "class_names = train_dataset.class_names\n",
        "print(\"\\nClass names:\\n\",class_names)"
      ],
      "metadata": {
        "id": "gcnfmJHNliIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Sample Image\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# Assumes dataset batch_size is at least 32.\n",
        "num_rows = 4\n",
        "num_cols = 8\n",
        "\n",
        "# Here we use the take() method to retrieve just the first batch of data from the training portion of the dataset.\n",
        "for image_batch, labels_batch in train_dataset.take(1):\n",
        "\n",
        "    # For the batch of images and the associated (one-hot encoded) labels,\n",
        "    # plot each of the images in the batch and the associated ground truth labels.\n",
        "    for idx in range(num_rows*num_cols):\n",
        "        ax = plt.subplot(num_rows, num_cols, idx + 1)\n",
        "        plt.imshow(image_batch[idx].numpy().astype(\"uint8\"))\n",
        "        truth_idx = np.nonzero(labels_batch[idx].numpy())\n",
        "        plt.title(class_names[truth_idx[0][0]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "ubiox4IllrVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model\n",
        "vgg16_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=TrainingConfig.LEARNING_RATE),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                    metrics=['accuracy'],\n",
        "                   )"
      ],
      "metadata": {
        "id": "k33C3-XqlvnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best model based on highest validation_accuracy.\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=TrainingConfig.CHECKPOINT_DIR,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_accuracy',\n",
        "                                                               mode='max',\n",
        "                                                               save_best_only=True,\n",
        "                                                              )"
      ],
      "metadata": {
        "id": "Rj0-6wJDlzpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model.\n",
        "training_results = vgg16_model.fit(train_dataset,\n",
        "                                   validation_data=valid_dataset,\n",
        "                                   epochs=TrainingConfig.EPOCHS,\n",
        "                                   callbacks=model_checkpoint_callback,\n",
        "                                  )"
      ],
      "metadata": {
        "id": "Jo5CEwzrl25L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training result\n",
        "def plot_results(metrics, ylabel=None, ylim=None, metric_name=None, color=None):\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 4))\n",
        "\n",
        "    if not (isinstance(metric_name, list) or isinstance(metric_name, tuple)):\n",
        "        metrics = [metrics,]\n",
        "        metric_name = [metric_name,]\n",
        "\n",
        "    for idx, metric in enumerate(metrics):\n",
        "        ax.plot(metric, color=color[idx])\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(ylabel)\n",
        "    plt.xlim([0, TrainingConfig.EPOCHS-1])\n",
        "    plt.ylim(ylim)\n",
        "    # Tailor x-axis tick marks\n",
        "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
        "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
        "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "    plt.grid(True)\n",
        "    plt.legend(metric_name)\n",
        "    plt.show(block=block_plot)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "AflYAn9Il5kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve training results.\n",
        "train_loss = training_results.history[\"loss\"]\n",
        "train_acc  = training_results.history[\"accuracy\"]\n",
        "valid_loss = training_results.history[\"val_loss\"]\n",
        "valid_acc  = training_results.history[\"val_accuracy\"]\n",
        "\n",
        "plot_results([ train_acc, valid_acc ],\n",
        "            ylabel=\"Accuracy\",\n",
        "            ylim = [0.0, 1.0],\n",
        "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
        "            color=[\"g\", \"b\"])\n",
        "\n",
        "max_loss = max(max(train_loss), max(valid_loss))\n",
        "\n",
        "plot_results([ train_loss, valid_loss ],\n",
        "            ylabel=\"Loss\",\n",
        "            ylim = [0.0, max_loss],\n",
        "            metric_name=[\"Training Loss\", \"Validation Loss\"],\n",
        "            color=[\"g\", \"b\"]);"
      ],
      "metadata": {
        "id": "_wzZJvXcl-yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "# Load saved model.\n",
        "# Final evaluation accuracy on the validation set.\n",
        "model = tf.keras.models.load_model(TrainingConfig.CHECKPOINT_DIR)\n",
        "print(f\"Model evaluation accuracy: {model.evaluate(valid_dataset)[1]*100.:.3f}\")"
      ],
      "metadata": {
        "id": "Pl-8DAkXmAp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_wrong_predictions(dataset, checkpoint_dir=None, checkpoint_version=0):\n",
        "\n",
        "    if not checkpoint_dir:\n",
        "        checkpoint_dir = os.path.join(os.getcwd(), TrainingConfig.checkpoint_dir, f\"version_{checkpoint_version}\")\n",
        "\n",
        "    # Load saved model.\n",
        "    model = keras.models.load_model(checkpoint_dir)\n",
        "\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    num_rows = 4\n",
        "    num_cols = 5\n",
        "    class_names = dataset.class_names\n",
        "    jdx = 0\n",
        "\n",
        "    # Evaluate all the batches.\n",
        "    for image_batch, labels_batch in dataset:\n",
        "\n",
        "        # Predictions for the current batch.\n",
        "        predictions = model.predict(image_batch)\n",
        "\n",
        "        # Loop over all the images in the current batch.\n",
        "        for idx in range(len(labels_batch)):\n",
        "\n",
        "            pred_idx = tf.argmax(predictions[idx]).numpy()\n",
        "            truth_idx = np.nonzero(labels_batch[idx].numpy())\n",
        "\n",
        "            # Plot the images with incorrect predictions\n",
        "            if pred_idx != truth_idx:\n",
        "\n",
        "                jdx += 1\n",
        "\n",
        "                if jdx > num_rows*num_cols:\n",
        "                    # Break from the loops if the maximum number of images have been plotted\n",
        "                    break\n",
        "\n",
        "                ax = plt.subplot(num_rows, num_cols, jdx)\n",
        "                title = str(class_names[truth_idx[0][0]]) + \" : \" + str(class_names[pred_idx])\n",
        "                title_obj = plt.title(title)\n",
        "                plt.setp(title_obj, color='r')\n",
        "                plt.axis(\"off\")\n",
        "                plt.imshow(image_batch[idx].numpy().astype(\"uint8\"))\n",
        "    return"
      ],
      "metadata": {
        "id": "6qjHBnWqmJPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_wrong_predictions(valid_dataset, TrainingConfig.CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "yPqHVIE-mJ5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
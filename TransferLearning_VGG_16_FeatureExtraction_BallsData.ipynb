{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etKtO5PumrJV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import zipfile\n",
        "import requests\n",
        "import glob as glob\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "from matplotlib.ticker import (\n",
        "    MultipleLocator, FormatStrFormatter\n",
        ")\n",
        "from dataclasses import dataclass\n",
        "\n",
        "block_plot = False\n",
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "SEED_VALUE = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def system_config():\n",
        "\n",
        "    # Get list of GPUs.\n",
        "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "    print(gpu_devices)\n",
        "\n",
        "    if len(gpu_devices) > 0:\n",
        "        print('Using GPU')\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "        # If there are any gpu devices, use first gpu.\n",
        "        tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
        "\n",
        "        # Grow the memory usage as it is needed by the process.\n",
        "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
        "\n",
        "        # Enable using cudNN.\n",
        "        os.environ['TF_USE_CUDNN'] = \"true\"\n",
        "    else:\n",
        "        print('Using CPU')\n",
        "\n",
        "system_config()"
      ],
      "metadata": {
        "id": "XZS5EgjkmyLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Extract data\n",
        "def download_file(url, save_name):\n",
        "    url = url\n",
        "    file = requests.get(url)\n",
        "\n",
        "    open(save_name, 'wb').write(file.content)"
      ],
      "metadata": {
        "id": "09Y1kJH-m0Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(zip_file=None):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print(\"Extracted all\")\n",
        "    except:\n",
        "        print(\"Invalid file\")"
      ],
      "metadata": {
        "id": "t14kf8Y-m35F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_file(\n",
        "    'https://www.dropbox.com/s/6nrjxr2ycnpcy63/dataset_balls.zip?dl=1',\n",
        "    'dataset_balls.zip'\n",
        ")\n",
        "\n",
        "unzip(zip_file='dataset_balls.zip')"
      ],
      "metadata": {
        "id": "hhPH7m5am5Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Training Configuration\n",
        "@dataclass(frozen=True)\n",
        "class DatasetConfig:\n",
        "    NUM_CLASSES: int = 10\n",
        "    IMG_HEIGHT:  int = 224\n",
        "    IMG_WIDTH:   int = 224\n",
        "    CHANNELS:    int = 3\n",
        "    BATCH_SIZE:  int = 32\n",
        "    DATA_ROOT_TRAIN:   str = 'dataset_balls/train'\n",
        "    DATA_ROOT_VALID:   str = 'dataset_balls/valid'\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainingConfig:\n",
        "    BATCH_SIZE:     int   = 32\n",
        "    EPOCHS:         int   = 51\n",
        "    LEARNING_RATE:  float = 0.0001\n",
        "    CHECKPOINT_DIR: str   = './saved_models_balls.keras'"
      ],
      "metadata": {
        "id": "VJES0cFxm74c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG Convolutional Base\n",
        "input_shape = (DatasetConfig.IMG_HEIGHT, DatasetConfig.IMG_WIDTH, DatasetConfig.CHANNELS)\n",
        "\n",
        "print('Loading model with ImageNet weights...')\n",
        "vgg16_conv_base = tf.keras.applications.vgg16.VGG16(input_shape=input_shape,\n",
        "                                                    include_top=False, # We will supply our own top.\n",
        "                                                    weights='imagenet',\n",
        "                                                   )\n",
        "# Set the `trainable` attribute of the convolutional base to `False` so that the weights are not changed.\n",
        "vgg16_conv_base.trainable = False\n",
        "print('All weights trainable, fine tuning...')\n",
        "\n",
        "# Top = false, to give our own dense layer, we just want the convolutional base layer"
      ],
      "metadata": {
        "id": "RjbgN3KInAuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg16_conv_base.summary())"
      ],
      "metadata": {
        "id": "Npy0wbhynJiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding classification layer\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
        "\n",
        "x = vgg16_conv_base(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "# The final `Dense` layer with the number of classes.\n",
        "outputs = layers.Dense(DatasetConfig.NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# The final model.\n",
        "vgg16_model = keras.Model(inputs, outputs)\n",
        "\n",
        "print(vgg16_model.summary())"
      ],
      "metadata": {
        "id": "g7EbIHKznQx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_dataset_from_directory(directory=DatasetConfig.DATA_ROOT_TRAIN,\n",
        "                                             batch_size=TrainingConfig.BATCH_SIZE,\n",
        "                                             seed=SEED_VALUE,\n",
        "                                             label_mode='categorical',\n",
        "                                             image_size=(DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT),\n",
        "                                             )\n",
        "\n",
        "valid_dataset = image_dataset_from_directory(directory=DatasetConfig.DATA_ROOT_VALID,\n",
        "                                             batch_size=TrainingConfig.BATCH_SIZE,\n",
        "                                             seed=SEED_VALUE,\n",
        "                                             label_mode='categorical',\n",
        "                                             image_size=(DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT),\n",
        "                                             )"
      ],
      "metadata": {
        "id": "pf_ucW9FnW7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample image\n",
        "class_names = train_dataset.class_names\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# Assumes dataset batch_size is at least 32.\n",
        "num_rows = 4\n",
        "num_cols = 8\n",
        "\n",
        "# Here we use the take() method to retrieve just the first batch of data from the training portion of the dataset.\n",
        "for image_batch, labels_batch in train_dataset.take(1):\n",
        "\n",
        "    # For the batch of images and the associated (one-hot encoded) labels,\n",
        "    # plot each of the images in the batch and the associated ground truth labels.\n",
        "    for idx in range(num_rows*num_cols):\n",
        "        ax = plt.subplot(num_rows, num_cols, idx + 1)\n",
        "        plt.imshow(image_batch[idx].numpy().astype(\"uint8\"))\n",
        "        truth_idx = np.nonzero(labels_batch[idx].numpy())\n",
        "        plt.title(class_names[truth_idx[0][0]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "FCyQ3jEVnYdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=TrainingConfig.LEARNING_RATE),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                    metrics=['accuracy'],\n",
        "                   )"
      ],
      "metadata": {
        "id": "9bc1cJolne1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best model based on highest validation_accuracy.\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=TrainingConfig.CHECKPOINT_DIR,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_accuracy',\n",
        "                                                               mode='max',\n",
        "                                                               save_best_only=True,\n",
        "                                                              )"
      ],
      "metadata": {
        "id": "V-zIhTYAnhsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model evaluation accuracy: {vgg16_model.evaluate(valid_dataset)[1]*100.:.3f}\")"
      ],
      "metadata": {
        "id": "oT9sDdV6njR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model.\n",
        "training_results = vgg16_model.fit(train_dataset,\n",
        "                                   validation_data=valid_dataset,\n",
        "                                   epochs=TrainingConfig.EPOCHS,\n",
        "                                   callbacks=model_checkpoint_callback,\n",
        "                                  )"
      ],
      "metadata": {
        "id": "zbD-GrwPnj16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(metrics, ylabel=None, ylim=None, metric_name=None, color=None):\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 4))\n",
        "\n",
        "    if not (isinstance(metric_name, list) or isinstance(metric_name, tuple)):\n",
        "        metrics = [metrics,]\n",
        "        metric_name = [metric_name,]\n",
        "\n",
        "    for idx, metric in enumerate(metrics):\n",
        "        ax.plot(metric, color=color[idx])\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(ylabel)\n",
        "    plt.xlim([0, TrainingConfig.EPOCHS-1])\n",
        "    plt.ylim(ylim)\n",
        "    # Tailor x-axis tick marks\n",
        "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
        "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
        "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "    plt.grid(True)\n",
        "    plt.legend(metric_name)\n",
        "    plt.show(block=block_plot)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "mLW9Ja7wnlmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve training results.\n",
        "train_loss = training_results.history[\"loss\"]\n",
        "train_acc  = training_results.history[\"accuracy\"]\n",
        "valid_loss = training_results.history[\"val_loss\"]\n",
        "valid_acc  = training_results.history[\"val_accuracy\"]\n",
        "\n",
        "plot_results([ train_acc, valid_acc ],\n",
        "            ylabel=\"Accuracy\",\n",
        "            ylim = [0.0, 1.0],\n",
        "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
        "            color=[\"g\", \"b\"])\n",
        "\n",
        "max_loss = 2.0\n",
        "\n",
        "plot_results([ train_loss, valid_loss ],\n",
        "            ylabel=\"Loss\",\n",
        "            ylim = [0.0, max_loss],\n",
        "            metric_name=[\"Training Loss\", \"Validation Loss\"],\n",
        "            color=[\"g\", \"b\"]);"
      ],
      "metadata": {
        "id": "k2NqfkdBnpH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "# Load saved model.\n",
        "# Final evaluation accuracy on the validation set.\n",
        "model = tf.keras.models.load_model(TrainingConfig.CHECKPOINT_DIR)\n",
        "print(f\"Model evaluation accuracy: {model.evaluate(valid_dataset)[1]*100.:.3f}\")"
      ],
      "metadata": {
        "id": "mXgjEarHnrHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_wrong_predictions(dataset, checkpoint_dir=None, checkpoint_version=0):\n",
        "\n",
        "    if not checkpoint_dir:\n",
        "        checkpoint_dir = os.path.join(os.getcwd(), TrainingConfig.checkpoint_dir, f\"version_{checkpoint_version}\")\n",
        "\n",
        "    # Load saved model.\n",
        "    model = tf.keras.models.load_model(checkpoint_dir)\n",
        "\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    num_rows = 4\n",
        "    num_cols = 5\n",
        "    class_names = dataset.class_names\n",
        "    jdx = 0\n",
        "\n",
        "    # Evaluate all the batches.\n",
        "    for image_batch, labels_batch in dataset:\n",
        "\n",
        "        # Predictions for the current batch.\n",
        "        predictions = model.predict(image_batch)\n",
        "\n",
        "        # Loop over all the images in the current batch.\n",
        "        for idx in range(len(labels_batch)):\n",
        "\n",
        "            pred_idx = tf.argmax(predictions[idx]).numpy()\n",
        "            truth_idx = np.nonzero(labels_batch[idx].numpy())\n",
        "\n",
        "            # Plot the images with incorrect predictions\n",
        "            if pred_idx != truth_idx:\n",
        "\n",
        "                jdx += 1\n",
        "\n",
        "                if jdx > num_rows*num_cols:\n",
        "                    # Break from the loops if the maximum number of images have been plotted\n",
        "                    break\n",
        "\n",
        "                ax = plt.subplot(num_rows, num_cols, jdx)\n",
        "                title = str(class_names[truth_idx[0][0]]) + \" : \" + str(class_names[pred_idx])\n",
        "                title_obj = plt.title(title)\n",
        "                plt.setp(title_obj, color='r')\n",
        "                plt.axis(\"off\")\n",
        "                plt.imshow(image_batch[idx].numpy().astype(\"uint8\"))\n",
        "    return"
      ],
      "metadata": {
        "id": "c98QMX-8nwJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_wrong_predictions(valid_dataset, TrainingConfig.CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "a53WZsI0nyXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}